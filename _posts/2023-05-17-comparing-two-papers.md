---
layout: post
title: Comparing two papers in a Computing field
subtitle: Research Methods and Professional Practice Activity
categories: Practice
tags: [research methods, research design, critical review]
---

 ![Comparison](/assets/images/banners/compare.jpg)<br>

In this post, I aim to compare two papers in the field of Computing to assess my proficiency 
in delivering a critical review of existing literature, research design, and methodology.<br>

I have selected two distinct research papers by separate groups of scholars. 
The first paper, titled "Detecting and Tracking Political Abuse in Social Media," 
was published in 2011 (Ratkiewicz et al., 2011), while the second, titled "Unpredictability of AI," 
was published in 2019 and had only one author (Yampolskiy, 2019). 
These two papers share only their connection to the field of Computing and have nothing else in common.<br>

Before starting the Research Methods and Professional Practice module at the University of Essex,
I would rather say that the first paper was more *"practical"*, whereas the second one leaned towards being *"theoretical"*. 
Nevertheless, throughout this module, my understanding of research practices has expanded a bit.<br>

It is challenging for me to determine the specific research designs chosen for both papers,
in accordance with British Research Methodology. 
The choice depends on the perspective from which the research results are evaluated. For example, on one hand, Ratkiewicz's group of scholars did not clearly define the problem; instead, they gained a better understanding of the situation regarding tracking political abuse in social media. This aligns with the *Exploratory* type of research. On the other hand, the paper is highly descriptive, examining elements in great detail within the specified research area, which suggests it is *Conclusive* research.<br>

Yampolskiy's paper on the Unpredictability of AI appears to be primarily a *Literature Review*. 
By utilizing numerous references, the author concludes that the inherent unpredictability 
of AI renders achieving 100% safety impossible. 
In this case, we can classify the method of data collection as *Secondary* research, 
whereas another paper represents *Primary* research, highlighting a contrast between the two approaches.<br>

Ratkiewicz et al. have devised a comprehensive framework, which examines user behaviour 
and the dissemination of ideas across diverse data feeds from Twitter in real-time. 
The paper entails a thorough practical analysis, wherein the scholars 
predominantly employ *Qualitative* research methods such as *Case Studies* and *Observations*, 
while also accumulating a substantial amount of data for *Quantitative* research purposes. 
Consequently, we can classify this group of researchers as utilising *Mixed* methods.<br>

I suppose, each paper substantiates its claims and conclusions by presenting explicit arguments and supporting evidence. <br>

[References](https://github.com/Vasilisalook/vasilisalook.github.io/blob/main/CompareReferences.txt)<br>

You are welcome to compare two papers by yourself: <br>
[Detecting and tracking political abuse in social media (Ratkiewicz et al., 2011)](https://github.com/Vasilisalook/vasilisalook.github.io/blob/main/Detecting%20and%20Tracking%20Political%20Abuse%20in%20Social%20Media.pdf)<br>
[Unpredictability of AI (Yampolskiy, 2019)](https://github.com/Vasilisalook/vasilisalook.github.io/blob/main/Yampolskiy%20Unpredictability%20of%20AI.pdf)

